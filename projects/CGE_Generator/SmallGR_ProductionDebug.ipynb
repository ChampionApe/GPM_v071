{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f468d5e-22d0-448b-8562-711934baa469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file _gams_py_gdb0.gdx is still active and was not deleted.\n",
      "The file _gams_py_gdb1.gdx is still active and was not deleted.\n"
     ]
    }
   ],
   "source": [
    "clean_up = True\n",
    "%run stdPackages.ipynb\n",
    "ws = gams.GamsWorkspace(working_directory=d['work']) # specify where you want to run the GAMS models from (here the repository referred to in d['work'])\n",
    "d['data'] = os.path.join(d['data'], 'IO2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e362b-d53d-43e8-8b21-dc53a7cc3e46",
   "metadata": {},
   "source": [
    "## GR18 Production, debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675c79c-eb75-4393-97b9-e144b59e8a50",
   "metadata": {},
   "source": [
    "Different attempts at diagnosing problems with the production module/data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a46782-bb4b-4e69-8686-e6acb95a8ad5",
   "metadata": {},
   "source": [
    "### Data/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79311479-68fb-444d-879d-aeb0eee650c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'smallGR' # name of model\n",
    "module = name+'_P' # name of module\n",
    "db_IO = GpyDB(pickle_path = os.path.join(d['data'], f'IO_{name}')) # load IO database named IO_name\n",
    "with open(f\"{d['data']}\\\\glob_{name}\",\"rb\") as file: # load global settings anmed glob_name\n",
    "    glob=pickle.load(file)\n",
    "db_m  = GpyDB(pickle_path = os.path.join(d['data'], 'db_'+module)) # load data with settings for production module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec1fb8-b9e9-4327-9c54-c4edf70d0fc5",
   "metadata": {},
   "source": [
    "Add time index to the IO data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261256bd-b99d-4154-a7aa-99b5cfef4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addT(symbol, t):\n",
    "    return adjMultiIndex.bc(symbol, t).reorder_levels(['t']+symbol.index.names if 't' not in symbol.index.names else symbol.index.names)\n",
    "[db_IO.__setitem__(k, addT(db_IO.get(k), glob.db['t'].vals)) for k in db_IO.getTypes(['variable','scalar_variable'])];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a704e5b-1861-475b-889f-0da28665af21",
   "metadata": {},
   "source": [
    "Add durable prices (for now, to solve static calibration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6447ef-7f5d-4fb0-b901-efd72d90c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_IO['pD'] = db_IO.get('pD_dur').combine_first(db_IO.get('pD'))\n",
    "db_IO['p'] = db_IO.get('pD_dur').groupby(['t','n']).mean().combine_first(db_IO.get('p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7eb75e-f2a1-4725-b342-7b09a6a4e239",
   "metadata": {},
   "source": [
    "### Sector-by-sector solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4e0d6-7d5c-4ae3-a44d-c68adf6dd170",
   "metadata": {},
   "source": [
    "Sector *other1:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2aadcf-ea37-4d1f-9268-47fb03412947",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = pd.Index(['other1'],name='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9dc7f3f-456f-4dfe-9ab4-b085655a7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest = adj.rc_pd(db_m['nestProduction'], sector)\n",
    "db_s = db_IO.copy()\n",
    "aggregateDB.subset_db(db_s, sector)\n",
    "tree = nestingTree.tree(name = 'CESnest', tree = nest.to_list()) # individual tree\n",
    "Tree = nestingTree.aggTree(name = 'stdProduction', trees = {tree.name: tree})(namespace = {n+'_input': n for n in db_s.get('n')})\n",
    "P = CGE_Production.Production(tree=Tree, glob = glob) # initialize module from nesting tree and global settings\n",
    "aggregateDB.subset_db(db_s, Tree.get('n')) # goes through all symbols in db_IO and only keep the elements that are in the set 'n' from Tree.db\n",
    "robust.robust_merge_dbs(P.s.db, db_s, priority = 'second') # Merge IO data into the database of the module; if a symbol is in both, prioritize records from the second database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5283490-0b14-460a-b9a5-c2740cb65673",
   "metadata": {},
   "source": [
    "Try to run one sector at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e7768a-834e-4ccd-9ba5-9d323a7b25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in db_IO.get('s_p'):\n",
    "    sector = pd.Index([s], name = 's')\n",
    "    # subset data:\n",
    "    nest = adj.rc_pd(db_m['nestProduction'], sector)\n",
    "    db_s = db_IO.copy()\n",
    "    aggregateDB.subset_db(db_s, sector)\n",
    "    tree = nestingTree.tree(name = 'CESnest', tree = nest.to_list()) # individual tree\n",
    "    Tree = nestingTree.aggTree(name = 'stdProduction', trees = {tree.name: tree})(namespace = {n+'_input': n for n in db_s.get('n')})\n",
    "    P = CGE_Production.Production(tree=Tree, glob = glob) # initialize module from nesting tree and global settings\n",
    "    aggregateDB.subset_db(db_s, Tree.get('n')) # goes through all symbols in db_IO and only keep the elements that are in the set 'n' from Tree.db\n",
    "    robust.robust_merge_dbs(P.s.db, db_s, priority = 'second') # Merge IO data into the database of the module; if a symbol is in both, prioritize records from the second database\n",
    "    v = valueShares.valueShares(Tree, db_s)\n",
    "    v.compile() # set up model structure, and make sure to initialize symbols if they are not yet defined in the database \n",
    "    v.write(); # write GAMS code used for the model\n",
    "    m = v.run(exportTo = d['work'],ws=ws) # solve the \"model\".\n",
    "    m.out_db.get('vD').index = m.out_db.get('vD').index.set_levels(m.out_db.get('vD').index.levels[1].astype(str), level = 's')\n",
    "    m.out_db.get('mu').index = m.out_db.get('mu').index.set_levels(m.out_db.get('mu').index.levels[1].astype(str), level = 's')\n",
    "    gpyDB.GpyDBs_AOM_Second(P.s.db, gpy(adj.rc_pd(m.out_db.get('vD'), P.get('int')).rename('qD'))) # set intermediate goods levels\n",
    "    gpyDB.GpyDBs_AOM_Second(P.s.db, gpy(m.out_db.get('mu').xs(P.get('t0')[0]).rename('mu'))) # set intermediate goods levels\n",
    "    P.s.db['tauS'] = adjMultiIndex.applyMult(db_s.get('TotalTax'), P.get('output')) / P.get('qS')\n",
    "    P.compile(initDB=True) # set up model structure, and make sure to initialize symbols if they are not yet defined in the database (initDB = True)\n",
    "    P.s.setstate('C') # set to calibration state\n",
    "    P.write(); # write GAMS code\n",
    "    mStatic = P.run(exportTo = d['work'],ws=ws,**{'cns': 'CONOPT4'}) # solve the model using CONOPT4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
