{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39bdfcd-4cc0-4143-9cf3-437668fb67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No clean-up of work-folder\n"
     ]
    }
   ],
   "source": [
    "%run StdPackages.ipynb\n",
    "os.chdir(d['py'])\n",
    "from IOfunctions import *\n",
    "os.chdir(d['curr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d624635-585a-4e38-a035-8267f076e519",
   "metadata": {},
   "source": [
    "# Running ```readIO``` with options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a79cc-f3f2-4593-adea-9fcd6280b07f",
   "metadata": {},
   "source": [
    "We can use the class ```readIO``` to perform the operations in ```readIO_tutorial``` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2693fce-c01f-459d-a8e6-f38d05295d3a",
   "metadata": {},
   "source": [
    "### Initialize and adjust settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1d565-6fc8-41d9-87e4-0d7a83fa0885",
   "metadata": {},
   "source": [
    "*Required settings:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50398df-b5a0-4366-8366-480f6a41cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'GR18'\n",
    "file_v = os.path.join(d['data'], 'IO2018_v.xlsx')\n",
    "file_i = os.path.join(d['data'], 'IO2018_I.xlsx')\n",
    "file_k = os.path.join(d['data'], 'IO2018_K.xlsx')\n",
    "file_mappings = os.path.join(d['data'], 'GR2018_mappings.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b11341-cbe5-4a95-a641-b43e8960e7f0",
   "metadata": {},
   "source": [
    "*For v:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2016e768-4674-496c-98d2-3ab5f050f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowMarkers = {'P': {'ref': 'Dansk produktion','offset': {}},\n",
    "              'M': {'ref': 'Import', 'offset': {}},\n",
    "              'OT': {'ref': 'Andre udenlandske transaktioner', 'offset': {}},\n",
    "              'PI': {'ref': 'Primære inputs', 'offset': {}},\n",
    "              'TI': {'ref': 'Input/ endelig anvendelse i køberpriser', 'offset': {}},\n",
    "              'PV': {'ref': 'Produktionsværdi', 'offset': {}}\n",
    "             }\n",
    "colMarkers = {'In': {'ref': 'Input i produktionen (Transaktionskode 2000)', 'offset': {'colE': -2}},\n",
    "              'C' : {'ref': 'Privat forbrug (Transaktions-kode 3110)', 'offset': {'colE': -1}},\n",
    "              'G_NPISH': {'ref': 'NPISH (Transaktionskode 3130)', 'offset': {}},\n",
    "              'G_MVPC' : {'ref': 'Markedsmæssigt individuelt offentligt forbrug (Transaktionskode 3141)', 'offset': {}},\n",
    "              'G_NMVPC': {'ref': 'Ikke markedsmæssigt individuelt offentligt forbrug (Transaktionskode 3142)', 'offset': {}},\n",
    "              'G_CPC':   {'ref': 'Kollektivt offentligt forbrug (Transaktionskode 3200)', 'offset': {}},\n",
    "              'I': {'ref': 'Faste bruttoinvesteringer', 'offset': {}},\n",
    "              'Other': {'ref': 'Andre Anvendelser', 'offset':{}},\n",
    "              'T': {'ref': 'Total'}\n",
    "             }\n",
    "category = {'taxCategories': ['Produktskatter og subsidier, netto', 'Moms', 'Andre produktionsskatter', 'Andre produktionssubsidier'],\n",
    "            'wageCategory' : 'Aflønning af ansatte',\n",
    "            'residualIncomeCategory': 'Overskud af produktionen og blandet indkomst',\n",
    "            'itoryCategories': ['5300','5200'],\n",
    "            'exportCategory': '6000'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb42dfa-dc11-40f2-95b6-e0cba8e1e07d",
   "metadata": {},
   "source": [
    "*For i:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d940c6da-351f-4ac2-9a0f-9548341c40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_i = {'rMarker': 'Investering i alt, købepriser',\n",
    "            'cMarkers': ['Investerende brancher', 'Total'],\n",
    "            'row': 0, 'col': 1, 'rowIndex': 3} # look for identifiers and sectors in these rows/columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfd8a3-fc3e-414a-899a-f2d5bf7253ec",
   "metadata": {},
   "source": [
    "*For k (similar to v):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1150a7-52d0-47c5-bc9a-8222d52063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_k = {'rMarker': {'init': {'ref': 'Investerende brancher', 'offset': {}},\n",
    "                        'end':  {'ref': 'Total', 'offset':{}}},\n",
    "            'cMarker': {'init': {'ref': 'Typer af durables', 'offset': {}},\n",
    "                        'end':  {'ref': 'Total', 'offset':{}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a657-b77a-4323-9c55-4b69de1fd193",
   "metadata": {},
   "source": [
    "*Initialize (note: this takes somewhere close to a second because the excel data has to be processed): Because of the default options, the following two lines initialize the same classes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771d7add-2f1f-4605-b3e6-2547a33f833c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['db', 'wb', 'IO', 'locs', 'blocks', 's'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I = readIO(name = name, file = file, kwargs_v = {'category': category, 'rowMarkers': rowMarkers, 'colMarkers': colMarkers}, kwargs_i = kwargs_i)\n",
    "I = readIO(name = name, file_v = file_v, file_i = file_i, file_k = file_k) # because of default options in the class, this is an equivalent statement\n",
    "I.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21820b61-a1da-404e-a373-2c4fd08c82ce",
   "metadata": {},
   "source": [
    "*If we want to use default options most of the time, we can adjust the settings in the initialization phase or after:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba882af3-3c9e-4470-9864-8558e3bcc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "I.s['v']['exportCategory'] = '5000' # change export category \n",
    "I.s['v']['exportCategory'] = category['exportCategory'] # change it back again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3177a43-f136-4004-a536-e84838b9357d",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf1aa98-1be6-4240-a4be-c923dec37c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.gpyDB.GpyDB at 0x1e94ceb71c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf894fe2-00f5-446a-8c42-71d79a87839f",
   "metadata": {},
   "source": [
    "# Squaring IO value, IO investment, and durables data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b7b02-6899-4fe3-9f68-561ad285c669",
   "metadata": {},
   "source": [
    "The data on values may be on a different level than investments/durables data. For the Danish case, for instance, we are able to distinguish between 146 sectors in the IO values data (```IO_v```), but only 69 in the data on investments/durables. Similarly, the data on values distinguishes between 12 categories of investment goods, while investment/durable data only has 7 types. If the three data sources are consistent, this step can be skipped. We proceed as follows:\n",
    "1. Define a mapping from the 69 to the 146 branch data. This is a so-called one-to-many mapping as it associates one category (69-level) with multiple categories in the other category (146 level). This is essentially a *disaggregation* of data. Doing this, we need some kind of distributional key that determines how the one sector is allocated onto the many. Here, we simply use the relative sizes of the subsectors. Another approach is to use residual income for this; however, as this variable may be negative  for some subsectors, this can give some pretty weird distributions.\n",
    "2. Define a mapping from the 12 investment goods to the 7. Sum over values and keep the 7-investment good level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6198ba9a-5770-4990-9db0-c7a458f83920",
   "metadata": {},
   "source": [
    "#### Mapping from 69 to 146 sector level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e3300-95e7-4615-acc4-7531b67bce0d",
   "metadata": {},
   "source": [
    "*Read mapping from 69 to 146 sector levels:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf479f4-ed68-4a9e-ac36-b287e6a0837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_mappings = read.simpleLoad(file_mappings)\n",
    "m = read.maps(wb_mappings['69to146'])['s69tos146'].vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d73a1-ba55-44f9-abca-41f7199ccfd9",
   "metadata": {},
   "source": [
    "*Force it to use strings in the mapping:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af6a068d-0a1b-41c6-96a2-e8a70912a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.set_levels([level.astype(str) for level in m.levels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40d0c4-d3c8-4281-b03c-ad4503b39167",
   "metadata": {},
   "source": [
    "*Create weights using the size the sectors:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b157e23-5d4f-49ec-9b42-37a932dcc30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectorValue = adjMultiIndex.applyMult( adj.rc_pd(I.db.get('vD').groupby('s').sum()+I.db.get('TotalTax'), I.db.get('s_p')),\n",
    "                                      m.rename(['sAgg','s']))\n",
    "weights = sectorValue / (sectorValue.groupby('sAgg').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306765c-7545-47c8-a0ed-cf330643143b",
   "metadata": {},
   "source": [
    "*Apply to ```vD_inv``` and ```vD_dur``` - the only two variables defined over the smaller 69 index: (NB: Only run this cell once!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421b4dba-54f6-4e29-a7c0-569717f6de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCheck = {'vD_inv': sum(I.db.get('vD_inv')),\n",
    "             'vD_dur': sum(I.db.get('vD_dur'))}\n",
    "I.db['vD_inv'] = (I.db.get('vD_inv').rename_axis(index = {'s':'sAgg'}) * weights).droplevel('sAgg')\n",
    "I.db['vD_dur'] = (I.db.get('vD_dur').rename_axis(index = {'s':'sAgg'}) * weights).droplevel('sAgg')\n",
    "for k in dataCheck:\n",
    "    assert abs(dataCheck[k]-sum(I.db.get(k)))<1e-6, f\"Disaggregation from 69 to 146 sector changed the sum of {k}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb934b9e-b063-4b47-bacc-a4094c03da83",
   "metadata": {},
   "source": [
    "#### Mapping from 12 to 7 investment goods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164c62b-b39f-493f-81d2-058e79e7ef92",
   "metadata": {},
   "source": [
    "*In this case, the aggregation may affect a lot of sets and variables. Thus, we use the more general ```aggregateDB``` class from ```pyDatabases.gpyDB_wheels``` to deal with this. In the case of the Danish data, we can infer the mapping from 12 to 7 investment goods from the names as follows from the following:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51438dd4-fe1f-4a84-93fb-8966ad5642b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfull = I.db.get('s_i') # original set, lots of indices\n",
    "ni = I.db.get('vD_inv').index.levels[0] # new index - fewer, aggregated indices\n",
    "syntax = ni[ni.str.endswith('x')].str.rstrip('x') \n",
    "subset = nfull[nfull.str.startswith(tuple(syntax))]\n",
    "nfull2ni = {k: k  if not k.startswith(tuple(syntax)) else k[:-1]+'x' for k in nfull} # mapping from full set to more aggregated one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910469b-b1dd-43ef-9b4d-93130eb6e000",
   "metadata": {},
   "source": [
    "*Apply mapping to all symbols in the database:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "920c7803-17ab-448a-9489-ae6cf9627088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.gpyDB.GpyDB at 0x1e94ceb71c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregateDB.readSets(I.db) # the aggDB method works through manipulations of sets s,n - this defines them by reading from other symbols in the database.\n",
    "m = pd.MultiIndex.from_tuples(nfull2ni.items(), names = ['s','sAgg']) # define mapping as multiindex\n",
    "m = m.union(adj.rc_pd(pd.MultiIndex.from_arrays([I.db.get('s'), I.db.get('s').rename('sAgg')]), ('not', m.droplevel('sAgg'))), sort = False) # all elements that are not in the mapping, fill in as a mapping on the form (x,x).\n",
    "aggregateDB.aggDB(I.db, m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
